{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "This assignment deals with using `textblob` and other open-source libraries to perform NLP-based analysis on documents using Python.  **All parts should use the same three documents (as outlined in Part 1 below).  In addition to your .ipynb and/or .py files, you must submit a report document (in .doc or .pdf format) that answers various questions below.** \n",
    "\n",
    "**Part 1:**<br> Select and download three texts of your choosing that satisfy the following criteria:th\n",
    "i. All texts should have the same media format (ex: 3 novels, 3 movie scripts, 3 news articles, etc.)\n",
    "ii. One of the three texts should have a **conceptual discrepancy** from the others.  In a nutshell, a conceptual discrepancy between works is a key feature or characteristic that distinguishes otherwise similar entities.  I am highly flexible as to what defines a discrepancy from one document to the next, but feel free to reach out if you are unsure.  Some examples are below:<br>\n",
    "a. Two non-fiction novels and one fiction novel <br>\n",
    "b. Two romantic comedy scripts and one horror script<br>\n",
    "c. Two sports news articles and one current events article<br>\n",
    "**Make sure you briefly descibe your documents and cite the conceptual discrepancy that you have chosen in a paragraph.** \n",
    "\n",
    "**Part 2:**<br>\n",
    "(a) Compute word counts for each of your documents after excluding English stop words (and optionally, performing lemmatization).<br>\n",
    "(b) Create and display a bar plot for each document that include word counts for the 25 most frequent words (after the above processing).<br>\n",
    "(c) Create and display a word cloud for each document (using a mask image of your choice) that includes only the 100 most frequent words.  Note that you'll likely want to use the approach outlined in Session 25 that utilizes the `fitwords` method, since you will want data consistent with those for part (b).<br>(d) Do you notice any difference between the document with a conceptual discrepancy relative to the others wrt (b) and/or (c) above?  Try to explain why or why not.<br>\n",
    "\n",
    "**Part 3:**<br>\n",
    "(a) Use **Textatistic** to compute the _average_ of the Flesch–Kincaid, Gunning Fog, SMOG, and Dale–Chall scores for each document.   \n",
    "(b) Are there noticeable differences among your documents's readability scores, and do you suspect any difference is present (or _should be_ present) based on your chosen conceptual discrepancy? \n",
    "\n",
    "**Part 4:**<br> \n",
    "(a) Use spaCy to compute the pairwise similarity between your documents (i.e. doc. 1 to doc. 2, doc. 1 to doc. 3, doc. 2 to doc. 3).<br>\n",
    "(b) Based on these similarity measures, is your document with the conceptual disparity comparatively similar to or different from the others?  Is this an expected result or not?\n",
    "\n",
    "**Part 5:**<br>\n",
    "(a) Use spaCy to find the named entities in your documents.<br>\n",
    "(b) Produce a bar plot for each document that includes the count for the 20 most common named entities (by name).<br>\n",
    "(c) Produce a second bar plot per document based on the counts of every named entity type (PERSON, ORG, etc.)<br>\n",
    "(d) Do you notice any meaningful differences (or similarities) among the documents wrt to these plots?  If so, explain what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
